{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Group Slums Data into Train and Validation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laruvinga/machinelearning/blob/master/Group_Slums_Data_into_Train_and_Validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oo03Jc43fenG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "import os\n",
        "import random\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "from queue import Queue\n",
        "from threading import Thread\n",
        "from time import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zJXeVikivz-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "53be38f5-184f-4959-c0e1-2ea43204dda5"
      },
      "source": [
        "# Mount google drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uE2Mu_Hsiyk8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define dir paths\n",
        "dataset_dir = \"/content/drive/My Drive/SatelliteML/Test_101\"\n",
        "tmp_dir = \"/tmp/\"\n",
        "images_extract_dir = tmp_dir + \"/32grid\"\n",
        "shapes_extract_dir = tmp_dir + \"/boundaries\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qu-WF4-9ujde",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download and unpack from google drive\n",
        "shutil.unpack_archive(dataset_dir + \"/32grid.tar.bz2\", tmp_dir)\n",
        "shutil.unpack_archive(dataset_dir + \"/boundaries.tar.bz2\", tmp_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vS3xf6_6woXK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "40eed7f0-6ada-4907-d728-a8cbd75d9f5c"
      },
      "source": [
        "# Count number of files extracted\n",
        "images_extract_count = len(os.listdir(images_extract_dir))\n",
        "shapes_extract_count = len(os.listdir(shapes_extract_dir))\n",
        "\n",
        "print(images_extract_count, \" image files extracted.\")\n",
        "print(shapes_extract_count, \" shape files extracted.\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99750  image files extracted.\n",
            "11  shape files extracted.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-q_YlNd160H",
        "colab_type": "text"
      },
      "source": [
        "### GROUP DATA IN CORRECT DIRECTORIES FROM IMAGES EXTRACT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RucoXqN16Ia",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f73130d8-be6b-4fdd-c533-e84772516d2c"
      },
      "source": [
        "# Install geojson\n",
        "!pip install geojson\n",
        "# Install affine\n",
        "!pip install Affine"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: geojson in /usr/local/lib/python3.6/dist-packages (2.5.0)\n",
            "Requirement already satisfied: Affine in /usr/local/lib/python3.6/dist-packages (2.2.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnyBOIGg2f3d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import libs\n",
        "from osgeo import gdal\n",
        "from osgeo import osr\n",
        "from osgeo import ogr\n",
        "from shapely.geometry import shape\n",
        "from shapely.geometry import Polygon\n",
        "import geojson\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import os\n",
        "from affine import Affine"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5gdniNV3Kht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "slums_shp = shapes_extract_dir + \"/slums.shp\"\n",
        "\n",
        "ngozi_dir = tmp_dir + \"/byo_ngozi\";\n",
        "sorted_valid_dir = ngozi_dir + \"/valid\"\n",
        "sorted_train_dir = ngozi_dir + \"/train\"\n",
        "train_dir = tmp_dir + \"/train_tmp\"\n",
        "\n",
        "train_slums_dir = train_dir + \"/slum\"\n",
        "train_noslums_dir = train_dir + \"/noslum\"\n",
        "\n",
        "sorted_train_slums_dir = sorted_train_dir + \"/slum\"\n",
        "sorted_train_noslums_dir = sorted_train_dir + \"/noslum\"\n",
        "sorted_valid_slums_dir = sorted_valid_dir + \"/slum\"\n",
        "sorted_valid_noslums_dir = sorted_valid_dir + \"/noslum\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uHlwnGu4luV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create train slums dir\n",
        "\n",
        "shutil.rmtree(train_slums_dir)\n",
        "os.makedirs(train_slums_dir)\n",
        "\n",
        "shutil.rmtree(sorted_train_slums_dir)\n",
        "os.makedirs(sorted_train_slums_dir)\n",
        "\n",
        "shutil.rmtree(sorted_valid_slums_dir)\n",
        "os.makedirs(sorted_valid_slums_dir)\n",
        "\n",
        "# Create train no slums dir\n",
        "\n",
        "shutil.rmtree(train_noslums_dir)\n",
        "os.makedirs(train_noslums_dir)\n",
        "\n",
        "shutil.rmtree(sorted_train_noslums_dir)\n",
        "os.makedirs(sorted_train_noslums_dir)\n",
        "\n",
        "shutil.rmtree(sorted_valid_noslums_dir)\n",
        "os.makedirs(sorted_valid_noslums_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uPAFY7j2xb1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5a4129bf-60f0-4b38-8876-0cb77dc43989"
      },
      "source": [
        "# Get slums extents shapefile and test features\n",
        "driver = ogr.GetDriverByName('ESRI Shapefile')\n",
        "dataSource = driver.Open(slums_shp, 0) # 0 means read-only. 1 means writeable.\n",
        "layer = dataSource.GetLayer()\n",
        "featureCount = layer.GetFeatureCount()\n",
        "print (featureCount)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "93\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcMq_7QX2pPd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate corner points of raster image using affine\n",
        "def GetCornerPoints(filename):\n",
        "  src = gdal.Open(filename)\n",
        "  \n",
        "  # get row and column size from raster\n",
        "  ncol = src.RasterXSize\n",
        "  nrow = src.RasterYSize\n",
        "  \n",
        "  # get transformation parameters\n",
        "  gt  = src.GetGeoTransform()\n",
        "  \n",
        "  # calculate affine transform\n",
        "  transform = Affine.from_gdal(*gt)\n",
        "  c0x, c0y = transform.c, transform.f  # upper left\n",
        "  c1x, c1y = transform * (0, nrow)     # lower left\n",
        "  c2x, c2y = transform * (ncol, nrow)  # lower right\n",
        "  c3x, c3y = transform * (ncol, 0)     # upper right\n",
        "  xs = (c0x, c1x, c2x, c3x)\n",
        "  ys = (c0y, c1y, c2y, c3y)\n",
        "  \n",
        "  # Get bounds of image\n",
        "  x1, y1, x3, y3 = min(xs), min(ys), max(xs), max(ys)\n",
        "  x2, y2, x4, y4 = x3, y1, x1, y3\n",
        "  return [(x1, y1), (x2, y2), (x3, y3), (x4, y4)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yn685-C93CwV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get polygons from shapefile\n",
        "def PointsIntersectPolygons(polygons, points):\n",
        "  # Change points to polygon\n",
        "  pointsPolygon = Polygon(points)\n",
        "  \n",
        "  for polygon in polygons:\n",
        "    if polygon.intersects(pointsPolygon):\n",
        "      return True\n",
        "  return False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhKqkGlV3HXp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get all polygons defining slum boundaries\n",
        "def GetSlumPolygons():\n",
        "  # Open shapefile using OGR\n",
        "  driver = ogr.GetDriverByName('ESRI Shapefile')\n",
        "  dataSource = driver.Open(slums_shp, 0) # 0 means read-only. 1 means writeable.\n",
        "  layer = dataSource.GetLayer()\n",
        "  featureCount = layer.GetFeatureCount()\n",
        "  polygons = []\n",
        "  \n",
        "  # Get all polygons and put in array\n",
        "  for i in range(0, featureCount):\n",
        "    feature = layer.GetFeature(i)\n",
        "    json = geojson.loads(feature.ExportToJson())\n",
        "    geom = shape(json[\"geometry\"])\n",
        "    polygons.append(geom)\n",
        "  # Return polygons found\n",
        "  return polygons"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvD-p9j43uxG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get all slum polygons\n",
        "polygons = GetSlumPolygons()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nl5QUqw325J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a50bf0a2-c42c-4926-c6b5-bd90d3d343e1"
      },
      "source": [
        "# Get all files in folder and label imagery based on boundaries\n",
        "pathlist = Path(images_extract_dir).glob('**/*.tif')\n",
        "slum = 0\n",
        "noslum = 0\n",
        "\n",
        "for path in pathlist:\n",
        "  # Check if test points intersect\n",
        "  image_path = str(path)\n",
        "  points = GetCornerPoints(image_path)\n",
        "  intersect = PointsIntersectPolygons(polygons, points)\n",
        "  if intersect:\n",
        "    # Move file to slums unbalanced set and count\n",
        "    slum += 1\n",
        "    shutil.move(image_path, train_slums_dir + \"/\" + os.path.basename(image_path))\n",
        "  else:\n",
        "    # Move file to no slums unbalanced set and count\n",
        "    noslum += 1\n",
        "    shutil.move(image_path, train_noslums_dir + \"/\" + os.path.basename(image_path))\n",
        "\n",
        "print (\"Images labelled as slum: \", slum)\n",
        "print (\"Images labelled as other: \", noslum)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Images labelled as slum:  39\n",
            "Images labelled as other:  99711\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWmwIUjnNztn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a58b7dfd-104b-4e68-a453-7369c3bda35d"
      },
      "source": [
        "# Pick random image\n",
        "print(random.choice(os.listdir(train_noslums_dir)))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32grid.84836.tif\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W70Pk4ebRBiv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sort_images(src_slums_dir, src_noslums_dir, dest_slums_dir, dest_noslums_dir, count):\n",
        "  \n",
        "  for i in range(0, count):\n",
        "    # Get image names\n",
        "    slum_image = random.choice(os.listdir(src_slums_dir))\n",
        "    noslum_image = random.choice(os.listdir(src_noslums_dir))\n",
        "\n",
        "    # Generate source paths\n",
        "    src_slum_image_path = src_slums_dir + \"/\" + slum_image\n",
        "    src_noslum_image_path = src_noslums_dir + \"/\" + noslum_image\n",
        "    dest_slum_image_path = dest_slums_dir + \"/\" + slum_image\n",
        "    dest_noslum_image_path = dest_noslums_dir + \"/\" + noslum_image\n",
        "\n",
        "    # Move image files\n",
        "    shutil.move(src_slum_image_path, dest_slum_image_path)\n",
        "    shutil.move(src_noslum_image_path, dest_noslum_image_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvYNrO5nOcX1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Move images to dataset dir\n",
        "count_valid = 10\n",
        "count_train = len(os.listdir(train_slums_dir)) - count_valid\n",
        "\n",
        "# Validation dataset\n",
        "sort_images(train_slums_dir, train_noslums_dir, sorted_valid_slums_dir, sorted_valid_noslums_dir, count_valid)\n",
        "\n",
        "# Train dataset\n",
        "sort_images(train_slums_dir, train_noslums_dir, sorted_train_slums_dir, sorted_train_noslums_dir, count_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLM64GlBTHvN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "52afda6d-a3f5-48f1-83e7-672cc05bd74b"
      },
      "source": [
        "print(len(os.listdir(sorted_valid_slums_dir)), \" slum validation images\")\n",
        "print(len(os.listdir(sorted_valid_noslums_dir)), \" no-slum validation images\")\n",
        "print(len(os.listdir(sorted_train_slums_dir)), \" slum train images\")\n",
        "print(len(os.listdir(sorted_train_noslums_dir)), \" no-slum train images\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10  slum validation images\n",
            "10  no-slum validation images\n",
            "29  slum train images\n",
            "29  no-slum train images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJdA5XeoUUKd",
        "colab_type": "text"
      },
      "source": [
        "### CONVERT GEO-TIF IMAGES TO GEO-JPEG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qj4454cUbFim",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convertFile(tiffFileName, jpegFilename):\n",
        "  # Options\n",
        "  options_list = [\n",
        "      '-of JPEG'\n",
        "  ] \n",
        "  options_string = \" \".join(options_list)\n",
        "  # Translate geo file\n",
        "  gdal.Translate(jpegFilename, tiffFileName, options=options_string)\n",
        "  #Remove converted tiff file\n",
        "  os.remove(tiffFileName)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EehYwqFlbHWm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def runConvertFile(tiff_image_path):\n",
        "  # Get base file name\n",
        "  base_filename = os.path.basename(tiff_image_path)\n",
        "  # Get jpeg image path as string\n",
        "  jpg_image_path = os.path.splitext(tiff_image_path)[0] + \".jpg\"\n",
        "  # Convert file\n",
        "  convertFile(tiff_image_path, jpg_image_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqDmQFVHVDFJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "61cd4391-ba06-4c7e-9b29-d96b079818c4"
      },
      "source": [
        "# All paths to convert\n",
        "data_dirs = [\n",
        "    sorted_valid_slums_dir,\n",
        "    sorted_valid_noslums_dir,\n",
        "    sorted_train_slums_dir,\n",
        "    sorted_train_noslums_dir\n",
        "]\n",
        "\n",
        "\n",
        "# Get all files in all data directories\n",
        "for data_dir in data_dirs:\n",
        "\n",
        "  # Get all tiff files to convert to jpg\n",
        "  # pathlist = Path(data_dir) #.glob('**/*.tif')\n",
        "  # Insert paths into queue\n",
        "  for path in os.listdir(data_dir):\n",
        "    if path.endswith('.tif'):\n",
        "      runConvertFile(data_dir + \"/\" + path)\n",
        "\n",
        "print(\"GeoTIFF to GeoJPEG conversion complete.\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GeoTIFF to GeoJPEG conversion complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0fFpmxqjOnY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c62c3152-66fe-43b3-a7cb-fc832079bcf1"
      },
      "source": [
        "# Archive images dataset\n",
        "shutil.make_archive(ngozi_dir, \"bztar\", tmp_dir)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/tmp/byo_ngozi.tar.bz2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3C7be-slzga",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a652db40-02ca-45ce-c8c7-598643cfec7e"
      },
      "source": [
        "shutil.move(ngozi_dir + \".tar.bz2\", dataset_dir + \"/byo_ngozi.tar.bz2\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/SatelliteML/Test_101/byo_ngozi.tar.bz2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    }
  ]
}